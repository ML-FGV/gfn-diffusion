{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-03T19:32:19.763620Z",
     "start_time": "2025-02-03T19:32:19.760098Z"
    }
   },
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "# Módulos customizados – certifique-se de que eles estejam disponíveis no seu ambiente\n",
    "from plot_utils import *\n",
    "from utils import set_seed, cal_subtb_coef_matrix, fig_to_image, get_gfn_optimizer, get_gfn_forward_loss, \\\n",
    "    get_gfn_backward_loss, get_exploration_std, get_name\n",
    "from buffer import ReplayBuffer\n",
    "from langevin import langevin_dynamics\n",
    "from models import GFN\n",
    "from gflownet_losses import *\n",
    "from energies import *\n",
    "from evaluations import *"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Configuração dos Hiperparâmetros\n",
    "\n",
    "Em notebooks é comum definirmos os parâmetros manualmente em vez de usar *argparse*.  \n",
    "A seguir, criamos um objeto `args` (do tipo `Namespace`) com os valores padrão.\n"
   ],
   "id": "ab776976e1cba2e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T19:32:25.654654Z",
     "start_time": "2025-02-03T19:32:25.647381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Em vez de usar argparse.parse_args(), definimos os parâmetros manualmente:\n",
    "args = argparse.Namespace(\n",
    "    lr_policy=1e-3,\n",
    "    lr_flow=1e-2,\n",
    "    lr_back=1e-3,\n",
    "    hidden_dim=64,\n",
    "    s_emb_dim=64,\n",
    "    t_emb_dim=64,\n",
    "    harmonics_dim=64,\n",
    "    batch_size=300,\n",
    "    buffer_size=300 * 100 * 2,\n",
    "    T=100,\n",
    "    epochs=25000,\n",
    "    subtb_lambda=2,\n",
    "    t_scale=5.0,\n",
    "    log_var_range=4.0,\n",
    "    energy='linreg',  # opções: 'vae' ou 'linreg'\n",
    "    mode_fwd=\"tb\",  # opções: 'tb', 'tb-avg', 'db', 'subtb', 'cond-tb-avg'\n",
    "    mode_bwd=\"tb\",  # opções: 'tb', 'tb-avg', 'mle', 'cond-tb-avg'\n",
    "    both_ways=False,\n",
    "    repeats=10,\n",
    "    local_search=False,\n",
    "    max_iter_ls=200,\n",
    "    burn_in=100,\n",
    "    ls_cycle=100,\n",
    "    ld_step=0.001,\n",
    "    ld_beta=5.0,\n",
    "    ld_schedule=False,\n",
    "    target_acceptance_rate=0.574,\n",
    "    beta=1.0,\n",
    "    rank_weight=1e-2,\n",
    "    prioritized=\"rank\",  # opções: 'none', 'reward', 'rank'\n",
    "    scheduler=False,\n",
    "    step_point=7000,\n",
    "    bwd=False,\n",
    "    exploratory=False,\n",
    "    sampling=\"buffer\",  # opções: 'sleep_phase', 'energy', 'buffer'\n",
    "    langevin=False,\n",
    "    langevin_scaling_per_dimension=False,\n",
    "    conditional_flow_model=False,\n",
    "    learn_pb=False,\n",
    "    pb_scale_range=0.1,\n",
    "    learned_variance=False,\n",
    "    partial_energy=False,\n",
    "    exploration_factor=0.1,\n",
    "    exploration_wd=False,\n",
    "    clipping=False,\n",
    "    lgv_clip=1e2,\n",
    "    gfn_clip=1e4,\n",
    "    zero_init=False,\n",
    "    pis_architectures=False,\n",
    "    lgv_layers=3,\n",
    "    joint_layers=2,\n",
    "    seed=12345,\n",
    "    weight_decay=1e-7,\n",
    "    use_weight_decay=False,\n",
    "    eval=False\n",
    ")\n",
    "\n",
    "# Configuração adicional\n",
    "eval_data_size = 300\n",
    "final_eval_data_size = 300\n",
    "plot_data_size = 16\n",
    "final_plot_data_size = 16\n",
    "\n",
    "if args.pis_architectures:\n",
    "    args.zero_init = True"
   ],
   "id": "3c63b8b3f172bdc0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Configuração do Ambiente\n",
    "\n",
    "Nesta célula, configuramos a semente para reprodutibilidade, o dispositivo de computação e a matriz de coeficientes.\n"
   ],
   "id": "edf72f354eba3e81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T19:32:29.160751Z",
     "start_time": "2025-02-03T19:32:29.151055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "set_seed(args.seed)\n",
    "if 'SLURM_PROCID' in os.environ:\n",
    "    args.seed += int(os.environ[\"SLURM_PROCID\"])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "coeff_matrix = cal_subtb_coef_matrix(args.subtb_lambda, args.T).to(device)\n",
    "\n",
    "# Se ambos os modos (forward e backward) estiverem ativos, desabilita o modo backward\n",
    "if args.both_ways and args.bwd:\n",
    "    args.bwd = False\n",
    "\n",
    "# Se a busca local estiver ativa, força ambos os modos\n",
    "if args.local_search:\n",
    "    args.both_ways = True"
   ],
   "id": "c1d9a7b2327ac5f7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Definição das Funções de Apoio\n",
    "\n",
    "Nesta seção definimos as funções que compõem o pipeline de treinamento:\n",
    "\n",
    "- **get_energy():** Inicializa o modelo de energia de acordo com o parâmetro `args.energy`.\n",
    "- **plot_step():** Gera e salva figuras com os dados reais, amostras do VAE e amostras do GFN (para o caso `vae`).  \n",
    "  *Nota: As referências ao WandB foram removidas.*\n",
    "- **eval_step():** Realiza a avaliação do modelo, calculando métricas como o log-partition function e a log-verossimilhança média.\n",
    "- **train_step(), fwd_train_step() e bwd_train_step():** Implementam os passos de treinamento (forward e backward).\n"
   ],
   "id": "f147342e46734f79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T19:32:32.297702Z",
     "start_time": "2025-02-03T19:32:32.281505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_energy():\n",
    "    if args.energy == 'vae':\n",
    "        energy = VAEEnergy(device=device, batch_size=args.batch_size)\n",
    "    elif args.energy == 'linreg':\n",
    "        energy = LinearEnergy(device=device, batch_size=args.batch_size)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Energia não implementada para este tipo.\")\n",
    "    return energy\n",
    "\n",
    "\n",
    "def plot_step(energy, gfn_model, name):\n",
    "    \"\"\"\n",
    "    Gera visualizações para o caso de energia 'vae' e salva os gráficos em arquivos PDF.\n",
    "    As imagens não são enviadas para WandB.\n",
    "    \"\"\"\n",
    "    if args.energy == 'vae':\n",
    "        batch_size = plot_data_size\n",
    "        real_data = energy.sample_evaluation_subset(batch_size)\n",
    "        fig_real_data, ax_real_data = get_vae_images(real_data.detach().cpu())\n",
    "\n",
    "        vae_samples_mu, vae_samples_logvar = energy.vae.encode(real_data)\n",
    "        vae_z = energy.vae.reparameterize(vae_samples_mu, vae_samples_logvar)\n",
    "        vae_samples = energy.vae.decode(vae_z)\n",
    "        fig_vae_samples, ax_vae_samples = get_vae_images(vae_samples.detach().cpu())\n",
    "\n",
    "        gfn_samples_z = gfn_model.sample(batch_size, energy.log_reward, real_data)\n",
    "        gfn_samples = energy.vae.decode(gfn_samples_z)\n",
    "        fig_gfn_samples, ax_gfn_samples = get_vae_images(gfn_samples.detach().cpu())\n",
    "\n",
    "        fig_real_data.savefig(f'{name}real_data.pdf', bbox_inches='tight')\n",
    "        fig_vae_samples.savefig(f'{name}vae_samples.pdf', bbox_inches='tight')\n",
    "        fig_gfn_samples.savefig(f'{name}gfn_samples.pdf', bbox_inches='tight')\n",
    "\n",
    "        # Retorna dicionário vazio (anteriormente, imagens eram enviadas via WandB)\n",
    "        return {}\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "\n",
    "def eval_step(eval_data, energy, gfn_model, final_eval=False, condition=None):\n",
    "    \"\"\"\n",
    "    Avalia o modelo calculando métricas de log-partition function e log-verossimilhança média.\n",
    "    \"\"\"\n",
    "    gfn_model.eval()\n",
    "    metrics = dict()\n",
    "    if final_eval:\n",
    "        init_state = torch.zeros(final_eval_data_size, energy.data_ndim).to(device)\n",
    "        samples, metrics['final_eval/log_Z'], metrics['final_eval/log_Z_lb'], metrics['final_eval/log_Z_learned'] = log_partition_function(\n",
    "            init_state, gfn_model, energy.log_reward, condition=condition)\n",
    "    else:\n",
    "        init_state = torch.zeros(eval_data_size, energy.data_ndim).to(device)\n",
    "        samples, metrics['eval/log_Z'], metrics['eval/log_Z_lb'], metrics['eval/log_Z_learned'] = log_partition_function(\n",
    "            init_state, gfn_model, energy.log_reward, condition=condition)\n",
    "    if eval_data is not None and condition is None:\n",
    "        if final_eval:\n",
    "            metrics['final_eval/mean_log_likelihood'] = mean_log_likelihood(eval_data, gfn_model, energy.log_reward,\n",
    "                                                                            condition=condition)\n",
    "        else:\n",
    "            metrics['eval/mean_log_likelihood'] = mean_log_likelihood(eval_data, gfn_model, energy.log_reward,\n",
    "                                                                      condition=condition)\n",
    "        metrics.update(get_sample_metrics(samples, eval_data, final_eval))\n",
    "    gfn_model.train()\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def train_step(energy, gfn_model, gfn_optimizer, it, exploratory, epochs, buffer, buffer_ls, exploration_factor,\n",
    "               exploration_wd, condition=None, repeats=10):\n",
    "    gfn_model.zero_grad()\n",
    "    exploration_std = get_exploration_std(it, exploratory, epochs, exploration_factor, exploration_wd)\n",
    "    \n",
    "    if args.both_ways:\n",
    "        if it % 2 == 0:\n",
    "            if args.sampling == 'buffer':\n",
    "                loss, states, _, _, log_r = fwd_train_step(energy, gfn_model, exploration_std, return_exp=True,\n",
    "                                                           condition=condition, repeats=repeats)\n",
    "\n",
    "                states = states[:, -1]\n",
    "                states = states.view(args.batch_size, repeats, -1)\n",
    "                log_r = log_r.view(args.batch_size, repeats)\n",
    "                states = states[torch.arange(args.batch_size), torch.argmax(log_r, dim=1)]\n",
    "                log_r = log_r[torch.arange(args.batch_size), torch.argmax(log_r, dim=1)]\n",
    "                buffer.add(states, log_r, condition=condition)\n",
    "            else:\n",
    "                loss = fwd_train_step(energy, gfn_model, exploration_std, condition=condition, repeats=repeats)\n",
    "        else:\n",
    "            loss = bwd_train_step(energy, gfn_model, buffer, buffer_ls, exploration_std, it=it, condition=condition,\n",
    "                                  repeats=repeats)\n",
    "    elif args.bwd:\n",
    "        loss = bwd_train_step(energy, gfn_model, buffer, buffer_ls, exploration_std, it=it, condition=condition,\n",
    "                              repeats=repeats)\n",
    "    else:\n",
    "        loss = fwd_train_step(energy, gfn_model, exploration_std, condition=condition, repeats=repeats)\n",
    "\n",
    "    loss.backward()\n",
    "    gfn_optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def fwd_train_step(energy, gfn_model, exploration_std, return_exp=False, condition=None, repeats=10):\n",
    "    init_state = torch.zeros(args.batch_size, energy.data_ndim).to(device)\n",
    "    loss = get_gfn_forward_loss(args.mode_fwd, init_state, gfn_model, energy.log_reward, coeff_matrix,\n",
    "                                exploration_std=exploration_std, return_exp=return_exp, condition=condition,\n",
    "                                repeats=repeats)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def bwd_train_step(energy, gfn_model, buffer, buffer_ls, exploration_std=None, it=0, condition=None, repeats=10):\n",
    "    if args.sampling == 'sleep_phase':\n",
    "        samples = gfn_model.sleep_phase_sample(args.batch_size, exploration_std, condition=condition).to(device)\n",
    "    elif args.sampling == 'energy':\n",
    "        samples = energy.sample(args.batch_size).to(device)\n",
    "    elif args.sampling == 'buffer':\n",
    "        if args.local_search:\n",
    "            if it % args.ls_cycle < 2:\n",
    "                samples, _, condition, _ = buffer.sample()\n",
    "                samples = samples.detach()\n",
    "                condition = condition.detach()\n",
    "                local_search_samples, log_r, condition = langevin_dynamics(samples, energy.log_reward, device, args,\n",
    "                                                                           condition=condition)\n",
    "                buffer_ls.add(local_search_samples.detach(), log_r.detach(), condition=condition)\n",
    "            samples, log_r, condition, _ = buffer_ls.sample()\n",
    "        else:\n",
    "            samples, _, condition, _ = buffer.sample().detach()\n",
    "\n",
    "    loss = get_gfn_backward_loss(args.mode_bwd, samples, gfn_model, energy.log_reward,\n",
    "                                 exploration_std=exploration_std, condition=condition, repeats=repeats)\n",
    "    return loss"
   ],
   "id": "3d4c33efa24001a8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Treinamento de GFN: Pipeline Desmembrado\n",
    "\n",
    "Esta sequência de células reproduz o pipeline de treinamento que estava encapsulado na função `train()`.  \n",
    "Cada célula representa uma etapa do processo:\n",
    "1. Preparação do ambiente e criação do diretório de salvamento.\n",
    "2. Inicialização do modelo de energia e das amostras de avaliação.\n",
    "3. Criação do modelo GFN e do otimizador (e, se configurado, o scheduler).\n",
    "4. Inicialização dos buffers de replay.\n",
    "5. Loop de treinamento com avaliação e salvamento periódico.\n",
    "6. Avaliação final e salvamento do modelo final.\n",
    "\n",
    "Os parâmetros são definidos previamente (por meio do objeto `args`) e as chamadas ao WandB foram removidas para execução local."
   ],
   "id": "86d02177223ba16c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T19:32:38.447107Z",
     "start_time": "2025-02-03T19:32:38.443938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "name = get_name(args)\n",
    "if not os.path.exists(name):\n",
    "    os.makedirs(name)"
   ],
   "id": "ef57d209de3228a8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Inicialização do Modelo de Energia e Dados de Avaliação\n",
    "\n",
    "Dependendo do tipo de energia configurado (por exemplo, `'vae'` ou `'linreg'`), amostramos os dados de avaliação."
   ],
   "id": "9b245ba645508f28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T19:32:40.156167Z",
     "start_time": "2025-02-03T19:32:40.143936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "energy = get_energy()\n",
    "if args.energy in ['vae', 'linreg']:\n",
    "    eval_data = energy.sample(eval_data_size, evaluation=True).to(device)\n",
    "    final_eval_data = energy.sample(final_eval_data_size, evaluation=True).to(device)\n",
    "else:\n",
    "    eval_data = energy.sample(eval_data_size).to(device)\n",
    "    final_eval_data = energy.sample(final_eval_data_size).to(device)\n",
    "\n",
    "# Para registro interno (não utilizado para log externo)\n",
    "config = args.__dict__\n",
    "config[\"Experiment\"] = f\"{args.energy}\""
   ],
   "id": "538b404ca4a5b0a5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 3. Inicialização do Modelo GFN e do Otimizador\n",
    "\n",
    "Aqui criamos o modelo GFN com os parâmetros definidos e configuramos o otimizador.  \n",
    "Se o scheduler estiver ativado, ele é criado para ajustar a taxa de aprendizado durante o treinamento.\n"
   ],
   "id": "c10b106699499258"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T19:32:41.952695Z",
     "start_time": "2025-02-03T19:32:41.940787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gfn_model = GFN(energy.data_ndim, args.s_emb_dim, args.hidden_dim, args.harmonics_dim, args.t_emb_dim,\n",
    "                trajectory_length=args.T, clipping=args.clipping, lgv_clip=args.lgv_clip, gfn_clip=args.gfn_clip,\n",
    "                langevin=args.langevin, learned_variance=args.learned_variance,\n",
    "                partial_energy=args.partial_energy, log_var_range=args.log_var_range,\n",
    "                pb_scale_range=args.pb_scale_range,\n",
    "                t_scale=args.t_scale, langevin_scaling_per_dimension=args.langevin_scaling_per_dimension,\n",
    "                conditional_flow_model=args.conditional_flow_model, learn_pb=args.learn_pb,\n",
    "                pis_architectures=args.pis_architectures, lgv_layers=args.lgv_layers,\n",
    "                joint_layers=args.joint_layers, zero_init=args.zero_init, device=device, energy=args.energy).to(device)\n",
    "\n",
    "gfn_optimizer = get_gfn_optimizer(gfn_model, args.lr_policy, args.lr_flow, args.lr_back, args.learn_pb,\n",
    "                                  args.conditional_flow_model, args.use_weight_decay, args.weight_decay,\n",
    "                                  args.energy)\n",
    "\n",
    "if args.scheduler:\n",
    "    lambda_function = lambda iteration: 0.1 if iteration >= args.step_point else 1.0\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(gfn_optimizer, lr_lambda=lambda_function)\n",
    "\n",
    "print(gfn_model)\n",
    "metrics = dict()"
   ],
   "id": "38575a040d5be81a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFN(\n",
      "  (t_model): TimeEncodingVAE(\n",
      "    (t_model): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (s_model): StateEncodingVAE(\n",
      "    (x_model): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=64, bias=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "      )\n",
      "      (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (d_model): DeepSet(\n",
      "    (phi): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (rho): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (joint_model): JointPolicyVAE(\n",
      "    (model): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "      )\n",
      "      (3): Linear(in_features=64, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (flow_model): FlowModelVAE(\n",
      "    (model): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "      )\n",
      "      (3): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (langevin_scaling_model): LangevinScalingModelVAE(\n",
      "    (lgv_model): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (1): Sequential(\n",
      "        (0): GELU(approximate='none')\n",
      "        (1): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): GELU(approximate='none')\n",
      "        (1): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "      (3): GELU(approximate='none')\n",
      "      (4): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Inicialização dos Buffers de Replay\n",
    "\n",
    "Cria-se o buffer padrão e um buffer específico para busca local (*local search*), se estiver configurado.\n"
   ],
   "id": "4913188097befc0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T19:32:44.767228Z",
     "start_time": "2025-02-03T19:32:44.760088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "buffer = ReplayBuffer(args.buffer_size, device, energy.log_reward, args.batch_size,\n",
    "                      data_ndim=energy.data_ndim, beta=args.beta, rank_weight=args.rank_weight,\n",
    "                      prioritized=args.prioritized)\n",
    "buffer_ls = ReplayBuffer(args.buffer_size, device, energy.log_reward, args.batch_size,\n",
    "                         data_ndim=energy.data_ndim, beta=args.beta, rank_weight=args.rank_weight,\n",
    "                         prioritized=args.prioritized)\n",
    "gfn_model.train()"
   ],
   "id": "7472e3e4d7d9c4ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GFN(\n",
       "  (t_model): TimeEncodingVAE(\n",
       "    (t_model): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (s_model): StateEncodingVAE(\n",
       "    (x_model): Sequential(\n",
       "      (0): Linear(in_features=3, out_features=64, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "      )\n",
       "      (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (d_model): DeepSet(\n",
       "    (phi): Sequential(\n",
       "      (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (rho): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (joint_model): JointPolicyVAE(\n",
       "    (model): Sequential(\n",
       "      (0): GELU(approximate='none')\n",
       "      (1): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "      )\n",
       "      (3): Linear(in_features=64, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (flow_model): FlowModelVAE(\n",
       "    (model): Sequential(\n",
       "      (0): GELU(approximate='none')\n",
       "      (1): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "      )\n",
       "      (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (langevin_scaling_model): LangevinScalingModelVAE(\n",
       "    (lgv_model): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): Sequential(\n",
       "        (0): GELU(approximate='none')\n",
       "        (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): GELU(approximate='none')\n",
       "        (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (3): GELU(approximate='none')\n",
       "      (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 5. Loop de Treinamento\n",
    "\n",
    "Nesta célula executamos o loop de treinamento.  \n",
    "Para cada iteração (época), são executados os seguintes passos:\n",
    "- Definição da condição de amostragem (se aplicável).\n",
    "- Execução de um passo de treinamento (forward ou backward) via `train_step`.\n",
    "- Atualização do scheduler, caso esteja configurado.\n",
    "- A cada 100 iterações, o modelo é avaliado e visualizações são geradas.\n",
    "- A cada 1000 iterações, o estado do modelo é salvo.\n"
   ],
   "id": "de5dfa17c0bb265d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T19:32:52.508374Z",
     "start_time": "2025-02-03T19:32:47.340824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in trange(args.epochs + 1):\n",
    "    # Define a condição para a amostragem, se o tipo de energia for 'vae' ou 'linreg'\n",
    "    if args.energy in ['vae', 'linreg']:\n",
    "        condition = energy.sample(args.batch_size)\n",
    "    else:\n",
    "        condition = None\n",
    "\n",
    "    metrics['train/loss'] = train_step(energy, gfn_model, gfn_optimizer, i, args.exploratory, args.epochs,\n",
    "                                       buffer, buffer_ls, args.exploration_factor, args.exploration_wd,\n",
    "                                       condition=condition, repeats=args.repeats)\n",
    "\n",
    "    if args.scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        if args.energy in ['vae', 'linreg']:\n",
    "            condition = energy.sample(eval_data_size, evaluation=True)\n",
    "        else:\n",
    "            condition = None\n",
    "        metrics.update(eval_step(eval_data, energy, gfn_model, final_eval=False, condition=condition))\n",
    "        print('Epoch:', i, ' - log_Z_lb:', metrics.get('eval/log_Z_lb'))\n",
    "        _ = plot_step(energy, gfn_model, name)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            torch.save(gfn_model.state_dict(), f'{name}model.pt')\n",
    "            torch.save({\n",
    "                'epoch': i,\n",
    "                'model_state_dict': gfn_model.state_dict(),\n",
    "                'optimizer_state_dict': gfn_optimizer.state_dict(),\n",
    "                'loss': metrics['train/loss'],\n",
    "            }, f'{name}model.pt')"
   ],
   "id": "b9d46a0f9ce83ce5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/25001 [00:01<8:53:34,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  - log_Z_lb: tensor(-52.2279)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/25001 [00:05<5:56:55,  1.17it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m      6\u001B[0m     condition \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m metrics[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain/loss\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43menergy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgfn_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgfn_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexploratory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer_ls\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexploration_factor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexploration_wd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mcondition\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcondition\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrepeats\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrepeats\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m args\u001B[38;5;241m.\u001B[39mscheduler:\n\u001B[1;32m     13\u001B[0m     scheduler\u001B[38;5;241m.\u001B[39mstep()\n",
      "Cell \u001B[0;32mIn[6], line 92\u001B[0m, in \u001B[0;36mtrain_step\u001B[0;34m(energy, gfn_model, gfn_optimizer, it, exploratory, epochs, buffer, buffer_ls, exploration_factor, exploration_wd, condition, repeats)\u001B[0m\n\u001B[1;32m     89\u001B[0m     loss \u001B[38;5;241m=\u001B[39m bwd_train_step(energy, gfn_model, buffer, buffer_ls, exploration_std, it\u001B[38;5;241m=\u001B[39mit, condition\u001B[38;5;241m=\u001B[39mcondition,\n\u001B[1;32m     90\u001B[0m                           repeats\u001B[38;5;241m=\u001B[39mrepeats)\n\u001B[1;32m     91\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 92\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mfwd_train_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43menergy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgfn_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexploration_std\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcondition\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcondition\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrepeats\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepeats\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     94\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     95\u001B[0m gfn_optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "Cell \u001B[0;32mIn[6], line 101\u001B[0m, in \u001B[0;36mfwd_train_step\u001B[0;34m(energy, gfn_model, exploration_std, return_exp, condition, repeats)\u001B[0m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mfwd_train_step\u001B[39m(energy, gfn_model, exploration_std, return_exp\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, condition\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, repeats\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m):\n\u001B[1;32m    100\u001B[0m     init_state \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(args\u001B[38;5;241m.\u001B[39mbatch_size, energy\u001B[38;5;241m.\u001B[39mdata_ndim)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m--> 101\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mget_gfn_forward_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode_fwd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgfn_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menergy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_reward\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcoeff_matrix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    102\u001B[0m \u001B[43m                                \u001B[49m\u001B[43mexploration_std\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexploration_std\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_exp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_exp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcondition\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcondition\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    103\u001B[0m \u001B[43m                                \u001B[49m\u001B[43mrepeats\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepeats\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    104\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/Documents/mestrado/projetos/gfn-diffusion/vae/utils.py:81\u001B[0m, in \u001B[0;36mget_gfn_forward_loss\u001B[0;34m(mode, init_state, gfn_model, log_reward, coeff_matrix, exploration_std, return_exp, condition, repeats)\u001B[0m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mget_gfn_forward_loss\u001B[39m(mode, init_state, gfn_model, log_reward, coeff_matrix, exploration_std\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, return_exp\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, condition\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, repeats\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m):\n\u001B[1;32m     80\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtb\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m---> 81\u001B[0m         loss \u001B[38;5;241m=\u001B[39m \u001B[43mfwd_tb\u001B[49m\u001B[43m(\u001B[49m\u001B[43minit_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgfn_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_reward\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexploration_std\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_exp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_exp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcondition\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcondition\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     82\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtb-avg\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     83\u001B[0m         loss \u001B[38;5;241m=\u001B[39m fwd_tb_avg(init_state, gfn_model, log_reward, exploration_std, return_exp\u001B[38;5;241m=\u001B[39mreturn_exp, condition\u001B[38;5;241m=\u001B[39mcondition)\n",
      "File \u001B[0;32m~/Documents/mestrado/projetos/gfn-diffusion/vae/gflownet_losses.py:6\u001B[0m, in \u001B[0;36mfwd_tb\u001B[0;34m(initial_state, gfn, log_reward_fn, exploration_std, return_exp, condition)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mfwd_tb\u001B[39m(initial_state, gfn, log_reward_fn, exploration_std\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, return_exp\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, condition\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m----> 6\u001B[0m     states, log_pfs, log_pbs, log_fs \u001B[38;5;241m=\u001B[39m \u001B[43mgfn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_trajectory_fwd\u001B[49m\u001B[43m(\u001B[49m\u001B[43minitial_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexploration_std\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_reward_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcondition\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m      9\u001B[0m         log_r \u001B[38;5;241m=\u001B[39m log_reward_fn(states[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], condition)\u001B[38;5;241m.\u001B[39mdetach()\n",
      "File \u001B[0;32m~/Documents/mestrado/projetos/gfn-diffusion/vae/models/gfn.py:140\u001B[0m, in \u001B[0;36mGFN.get_trajectory_fwd\u001B[0;34m(self, s, exploration_std, log_r, condition)\u001B[0m\n\u001B[1;32m    137\u001B[0m states \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros((bsz, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrajectory_length \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdim), device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrajectory_length):\n\u001B[0;32m--> 140\u001B[0m     pfs, flow \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_next_state\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_r\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcondition\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    141\u001B[0m     pf_mean, pflogvars \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msplit_params(pfs)\n\u001B[1;32m    143\u001B[0m     logf[:, i] \u001B[38;5;241m=\u001B[39m flow\n",
      "File \u001B[0;32m~/Documents/mestrado/projetos/gfn-diffusion/vae/models/gfn.py:106\u001B[0m, in \u001B[0;36mGFN.predict_next_state\u001B[0;34m(self, s, t, log_r, condition)\u001B[0m\n\u001B[1;32m    104\u001B[0m         s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ms_model(s, condition)\n\u001B[1;32m    105\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 106\u001B[0m         condition \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43md_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcondition\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    107\u001B[0m         s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ms_model(s, condition)\n\u001B[1;32m    108\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/basis-conditional-GflowNets/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/basis-conditional-GflowNets/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/mestrado/projetos/gfn-diffusion/vae/models/architectures.py:375\u001B[0m, in \u001B[0;36mDeepSet.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    374\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x : Float[Tensor, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch set_size s_dim\u001B[39m\u001B[38;5;124m\"\u001B[39m]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Float[Tensor, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch out_dim\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m--> 375\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mphi\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    376\u001B[0m     x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39msum(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    377\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrho(x)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/basis-conditional-GflowNets/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/basis-conditional-GflowNets/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/basis-conditional-GflowNets/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/basis-conditional-GflowNets/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/basis-conditional-GflowNets/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/basis-conditional-GflowNets/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 116\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 6. Avaliação Final e Salvamento do Modelo\n",
    "\n",
    "Após o término do treinamento, realizamos uma avaliação final do modelo e salvamos o estado final.\n"
   ],
   "id": "f3448041222c1d03"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if args.energy in ['vae', 'linreg']:\n",
    "    condition = energy.sample(eval_data_size, evaluation=True)\n",
    "else:\n",
    "    condition = None\n",
    "\n",
    "eval_results = eval_step(final_eval_data, energy, gfn_model, final_eval=True, condition=condition)\n",
    "metrics.update(eval_results)\n",
    "if 'tb-avg' in args.mode_fwd or 'tb-avg' in args.mode_bwd:\n",
    "    if 'final_eval/log_Z_learned' in metrics:\n",
    "        del metrics['final_eval/log_Z_learned']\n",
    "\n",
    "torch.save({\n",
    "    'epoch': i,\n",
    "    'model_state_dict': gfn_model.state_dict(),\n",
    "    'optimizer_state_dict': gfn_optimizer.state_dict(),\n",
    "    'loss': metrics['train/loss'],\n",
    "}, f'{name}model_final.pt')"
   ],
   "id": "3f7890ec9d73eb48"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
